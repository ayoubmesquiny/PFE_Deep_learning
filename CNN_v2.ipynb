{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directories and image dimensions\n",
    "img_width = 1280\n",
    "img_height = 720\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your data directory\n",
    "data_dir = \"C:/Users/DELL/Desktop/datatest/D-E\"\n",
    "\n",
    "# Get the list of all folders names\n",
    "image_files = os.listdir(data_dir)\n",
    "print(\"All folders names:\", image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all pass image file names\n",
    "pass_dir = os.path.join(data_dir, \"pass\")\n",
    "pass_images = [os.path.join(pass_dir, file) for file in os.listdir(pass_dir)]\n",
    "\n",
    "# Print the lists of pass and fail image file names\n",
    "print(\"Pass images:\", pass_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all fail image file names\n",
    "fail_dir = os.path.join(data_dir, \"fail\")\n",
    "fail_images = [os.path.join(fail_dir, file) for file in os.listdir(fail_dir)]\n",
    "\n",
    "# Print the lists of pass and fail image file names\n",
    "print(\"Fail images:\", fail_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets (70% train, 30% test)\n",
    "pass_train, pass_test = train_test_split(pass_images, test_size=0.3, random_state=42)\n",
    "fail_train, fail_test = train_test_split(fail_images, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create the train and test directories\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "os.makedirs(os.path.join(train_dir, \"pass\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(train_dir, \"fail\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, \"pass\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, \"fail\"), exist_ok=True)\n",
    "\n",
    "# Copy the pass images to the train and test directories\n",
    "for file in pass_train:\n",
    "    dest_file = os.path.join(train_dir, \"pass\", os.path.basename(file))\n",
    "    if not os.path.exists(dest_file):\n",
    "        shutil.copy(file, dest_file)\n",
    "for file in pass_test:\n",
    "    dest_file = os.path.join(test_dir, \"pass\", os.path.basename(file))\n",
    "    if not os.path.exists(dest_file):\n",
    "        shutil.copy(file, dest_file)\n",
    "\n",
    "# Copy the fail images to the train and test directories\n",
    "for file in fail_train:\n",
    "    dest_file = os.path.join(train_dir, \"fail\", os.path.basename(file))\n",
    "    if not os.path.exists(dest_file):\n",
    "        shutil.copy(file, dest_file)\n",
    "for file in fail_test:\n",
    "    dest_file = os.path.join(test_dir, \"fail\", os.path.basename(file))\n",
    "    if not os.path.exists(dest_file):\n",
    "        shutil.copy(file, dest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# Block 2\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# Flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data generators for image augmentation and rescaling\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    shear_range=0.2, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing data\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping callback\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_data, epochs=10, validation_data=test_data,callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
