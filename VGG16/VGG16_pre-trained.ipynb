{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from keras.utils import plot_model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the data folder into : Train and Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your data directory\n",
    "data_dir = \"C:/Users/DELL/Desktop/datatest/D-E\"\n",
    "\n",
    "# Get the list of all folders names\n",
    "image_files = os.listdir(data_dir)\n",
    "print(\"All folders names:\", image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all pass image file names\n",
    "pass_dir = os.path.join(data_dir, \"pass\")\n",
    "pass_images = [os.path.join(pass_dir, file) for file in os.listdir(pass_dir)]\n",
    "\n",
    "# Print the lists of pass and fail image file names\n",
    "print(\"Pass images:\", pass_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all fail image file names\n",
    "fail_dir = os.path.join(data_dir, \"fail\")\n",
    "fail_images = [os.path.join(fail_dir, file) for file in os.listdir(fail_dir)]\n",
    "\n",
    "# Print the lists of pass and fail image file names\n",
    "print(\"Fail images:\", fail_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets (70% train, 30% test)\n",
    "pass_train, pass_test = train_test_split(pass_images, test_size=0.3, random_state=42)\n",
    "fail_train, fail_test = train_test_split(fail_images, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create the train and test directories\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "os.makedirs(os.path.join(train_dir, \"pass\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(train_dir, \"fail\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, \"pass\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, \"fail\"), exist_ok=True)\n",
    "\n",
    "# Copy the pass images to the train and test directories\n",
    "for file in pass_train:\n",
    "    dest_file = os.path.join(train_dir, \"pass\", os.path.basename(file))\n",
    "    if not os.path.exists(dest_file):\n",
    "        shutil.copy(file, dest_file)\n",
    "for file in pass_test:\n",
    "    dest_file = os.path.join(test_dir, \"pass\", os.path.basename(file))\n",
    "    if not os.path.exists(dest_file):\n",
    "        shutil.copy(file, dest_file)\n",
    "\n",
    "# Copy the fail images to the train and test directories\n",
    "for file in fail_train:\n",
    "    dest_file = os.path.join(train_dir, \"fail\", os.path.basename(file))\n",
    "    if not os.path.exists(dest_file):\n",
    "        shutil.copy(file, dest_file)\n",
    "for file in fail_test:\n",
    "    dest_file = os.path.join(test_dir, \"fail\", os.path.basename(file))\n",
    "    if not os.path.exists(dest_file):\n",
    "        shutil.copy(file, dest_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input image size and number of classes\n",
    "img_width = 1280\n",
    "img_height = 720\n",
    "batch_size = 32\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(\n",
    "    weights='imagenet', # Load pre-trained weights from the ImageNet dataset\n",
    "    include_top=False, # Set to False to exclude the top fully connected layers from the model\n",
    "    input_shape=(img_width, img_height, 3) # The input shape of the images\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the weights of the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a new model on top of the pre-trained VGG16 model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "# flatten the output of the VGG16 base model\n",
    "model.add(Flatten())\n",
    "# add dense layers with dropout and L2 regularization\n",
    "model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model architecture\n",
    "plot_model(model, to_file='VGG19_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = SGD(lr=1e-4, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data generators for image augmentation and rescaling\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range=(0.8, 1.2),\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing data\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping callback\n",
    "early_stop = EarlyStopping(monitor=['val_loss', 'val_accuracy'], patience=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define learning rate schedule : define a step decay function that reduces the learning rate by a factor of 0.5 every 10 epochs\n",
    "def step_decay(epoch):\n",
    "\tinitial_lr = 0.001\n",
    "\tdrop = 0.5\n",
    "\tepochs_drop = 10.0\n",
    "\tlr = initial_lr * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create learning rate scheduler\n",
    "lr_scheduler = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data, \n",
    "    epochs=1000, \n",
    "    steps_per_epoch=train_data.n // train_data.batch_size,\n",
    "    validation_data=test_data,\n",
    "    validation_steps=test_data.n // test_data.batch_size,\n",
    "    callbacks=[early_stop, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the training and validation loss and accuracy over the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Seaborn style\n",
    "sns.set_style(\"darkgrid\")\n",
    "# Plot the training and validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Seaborn style\n",
    "sns.set_style(\"darkgrid\")\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the accuracy plot to a file\n",
    "plt.savefig('model_vgg16_accuracy.png')\n",
    "# Save the accuracy plot to a file\n",
    "plt.savefig('model_vgg16_loss.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
